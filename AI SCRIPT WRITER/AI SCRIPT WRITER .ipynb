{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c55fb1f2",
      "metadata": {
        "id": "c55fb1f2"
      },
      "source": [
        "\n",
        "# AI Script Rewriter for YouTube / Instagram Creators (Gemini-Powered)\n",
        "\n",
        "This notebook implements a multi-agent AI system that rewrites rough creator scripts into:\n",
        "- Strong hooks  \n",
        "- Optimised structure  \n",
        "- SEO-aware metadata  \n",
        "- Tone-adjusted, ready-to-record script  \n",
        "- Thumbnail caption ideas  \n",
        "\n",
        "The agents are powered by Google Gemini via the `google-generativeai` Python SDK.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e26d0bf",
      "metadata": {
        "id": "5e26d0bf"
      },
      "source": [
        "\n",
        "## 0. Environment Setup\n",
        "\n",
        "Run the cell below to install the Gemini SDK (if needed) and configure your API key.\n",
        "\n",
        "- Generate an API key from the Google AI Studio dashboard.  \n",
        "- Keep it private and never hard-code it in code you share publicly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b535cef2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b535cef2",
        "outputId": "400ee5ab-6587-44fd-bfed-d2d908af3bdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paste your GEMINI API key (input hidden): ··········\n",
            "Gemini client configured with model: models/gemini-2.5-flash\n"
          ]
        }
      ],
      "source": [
        "!pip install -q google-generativeai\n",
        "\n",
        "import os\n",
        "from getpass import getpass\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Configure your Gemini API key\n",
        "if \"GEMINI_API_KEY\" not in os.environ or not os.environ[\"GEMINI_API_KEY\"]:\n",
        "    os.environ[\"GEMINI_API_KEY\"] = getpass(\"Paste your GEMINI API key (input hidden): \")\n",
        "\n",
        "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
        "\n",
        "# Choose a model: \"gemini-1.5-flash\" (fast, cheap) or \"gemini-1.5-pro\" (stronger, more expensive)\n",
        "MODEL_NAME = \"models/gemini-2.5-flash\" # Updated to an available model\n",
        "model = genai.GenerativeModel(MODEL_NAME)\n",
        "\n",
        "print(\"Gemini client configured with model:\", MODEL_NAME)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f33ad9b",
      "metadata": {
        "id": "3f33ad9b"
      },
      "source": [
        "\n",
        "## 1. Core Data Models and Base Agent Class\n",
        "\n",
        "These classes define the shared data structures and the abstract `Agent` interface used by all agents.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3ef56f5e",
      "metadata": {
        "id": "3ef56f5e"
      },
      "outputs": [],
      "source": [
        "\n",
        "from abc import ABC, abstractmethod\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, Any, List\n",
        "\n",
        "@dataclass\n",
        "class ScriptInput:\n",
        "    topic: str\n",
        "    draft_script: str\n",
        "    platform: str  # \"youtube\" / \"instagram\" / \"tiktok\"\n",
        "    tone: str      # e.g. \"friendly\", \"hype\", \"professional\"\n",
        "\n",
        "@dataclass\n",
        "class ScriptOutput:\n",
        "    hooks: List[str]\n",
        "    structured_script: str\n",
        "    seo_metadata: Dict[str, Any]\n",
        "    final_script: str\n",
        "    thumbnail_captions: List[str]\n",
        "\n",
        "class Agent(ABC):\n",
        "    # Abstract base class for all agents in the pipeline.\n",
        "    @abstractmethod\n",
        "    def run(self, state: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        '''\n",
        "        Takes the current pipeline state and returns an updated dictionary.\n",
        "        '''\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "609cbbb3",
      "metadata": {
        "id": "609cbbb3"
      },
      "source": [
        "\n",
        "## 2. Ingestion & Analysis Agent\n",
        "\n",
        "One-liner: Cleans and normalises the raw draft, extracting topic, platform, tone, and key points into a structured state.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a9b4abf1",
      "metadata": {
        "id": "a9b4abf1"
      },
      "outputs": [],
      "source": [
        "\n",
        "class IngestionAgent(Agent):\n",
        "    # Basic ingestion agent. You can later extend this to use Gemini for richer key-point extraction.\n",
        "    def run(self, state: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        script_input: ScriptInput = state[\"input\"]\n",
        "\n",
        "        # Simple placeholder key-point extraction (could be replaced by a Gemini call)\n",
        "        key_points = [line.strip(\"-• \").strip()\n",
        "                      for line in script_input.draft_script.splitlines()\n",
        "                      if line.strip()]\n",
        "\n",
        "        state[\"analysis\"] = {\n",
        "            \"topic\": script_input.topic,\n",
        "            \"platform\": script_input.platform.lower(),\n",
        "            \"tone\": script_input.tone,\n",
        "            \"key_points\": key_points,\n",
        "            \"current_script\": script_input.draft_script\n",
        "        }\n",
        "        return state\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7581b76d",
      "metadata": {
        "id": "7581b76d"
      },
      "source": [
        "\n",
        "## 3. Hook Generator Agent\n",
        "\n",
        "One-liner: Uses Gemini to generate multiple strong, scroll-stopping hooks tailored to topic, platform and tone.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b938f056",
      "metadata": {
        "id": "b938f056"
      },
      "outputs": [],
      "source": [
        "\n",
        "class HookGeneratorAgent(Agent):\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def run(self, state: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        analysis = state[\"analysis\"]\n",
        "        topic = analysis[\"topic\"]\n",
        "        platform = analysis[\"platform\"]\n",
        "        tone = analysis[\"tone\"]\n",
        "\n",
        "        prompt = f'''You are an expert {platform} content hook writer.\n",
        "\n",
        "Topic: {topic}\n",
        "Platform: {platform}\n",
        "Desired tone: {tone}\n",
        "\n",
        "Generate 7 very strong, scroll-stopping hooks.\n",
        "- Each hook max 15 words.\n",
        "- No hashtags.\n",
        "- Make them punchy and emotionally engaging.\n",
        "Return them as a numbered list.\n",
        "'''\n",
        "\n",
        "        response = self.model.generate_content(prompt)\n",
        "        text = response.text or \"\"\n",
        "\n",
        "        hooks = []\n",
        "        for line in text.splitlines():\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            # Remove leading bullets / numbers like \"1.\" or \"-\"\n",
        "            line = line.lstrip(\"-•\").strip()\n",
        "            if line and line[0].isdigit():\n",
        "                parts = line.split(maxsplit=1)\n",
        "                if len(parts) == 2:\n",
        "                    line = parts[1]\n",
        "            if line:\n",
        "                hooks.append(line)\n",
        "\n",
        "        state[\"hooks\"] = hooks\n",
        "        return state\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee474f16",
      "metadata": {
        "id": "ee474f16"
      },
      "source": [
        "\n",
        "## 4. Structure Optimiser Agent\n",
        "\n",
        "One-liner: Asks Gemini to transform the rough draft into a structured script (hook, intro, sections, CTAs) in JSON form.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ef372173",
      "metadata": {
        "id": "ef372173"
      },
      "outputs": [],
      "source": [
        "\n",
        "import json\n",
        "\n",
        "class StructureOptimizerAgent(Agent):\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def run(self, state: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        analysis = state[\"analysis\"]\n",
        "        draft = analysis[\"current_script\"]\n",
        "        platform = analysis[\"platform\"]\n",
        "        hooks = state.get(\"hooks\", [])\n",
        "\n",
        "        prompt = f'''You are a script doctor for {platform} creators.\n",
        "\n",
        "Take this rough draft script and turn it into a clear, structured script\n",
        "with the following sections:\n",
        "1. Hook\n",
        "2. Fast intro (why this matters)\n",
        "3. Main sections (3-5 logical steps or ideas)\n",
        "4. Soft CTA (engagement)\n",
        "5. Strong CTA (subscribe/follow etc.)\n",
        "\n",
        "Use one of these hooks if they fit, otherwise improve them:\n",
        "{hooks}\n",
        "\n",
        "Draft script:\n",
        "\"\"\"{draft}\"\"\"\n",
        "\n",
        "Return output in this JSON format ONLY:\n",
        "\n",
        "{{\n",
        "  \"hook\": \"...\",\n",
        "  \"intro\": \"...\",\n",
        "  \"sections\": [\n",
        "    {{\"title\": \"...\", \"content\": \"...\"}}\n",
        "  ],\n",
        "  \"cta_soft\": \"...\",\n",
        "  \"cta_main\": \"...\"\n",
        "}}\n",
        "'''\n",
        "\n",
        "        response = self.model.generate_content(prompt)\n",
        "        raw = response.text\n",
        "\n",
        "        try:\n",
        "            structure = json.loads(raw)\n",
        "        except Exception:\n",
        "            # Fallback: try to extract JSON between first { and last }\n",
        "            if \"{\" in raw and \"}\" in raw:\n",
        "                raw_json = raw[raw.find(\"{\"): raw.rfind(\"}\") + 1]\n",
        "                structure = json.loads(raw_json)\n",
        "            else:\n",
        "                raise ValueError(\"Could not parse JSON structure from Gemini response:\\n\" + raw)\n",
        "\n",
        "        state[\"structure\"] = structure\n",
        "        return state\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff9c9dd4",
      "metadata": {
        "id": "ff9c9dd4"
      },
      "source": [
        "\n",
        "## 5. SEO Keyword Injection Agent\n",
        "\n",
        "One-liner: Uses Gemini to generate SEO keywords, titles, description and tags based on the topic and platform.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "404b8a35",
      "metadata": {
        "id": "404b8a35"
      },
      "outputs": [],
      "source": [
        "\n",
        "class SEOKeywordAgent(Agent):\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def run(self, state: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        topic = state[\"analysis\"][\"topic\"]\n",
        "        platform = state[\"analysis\"][\"platform\"]\n",
        "\n",
        "        prompt = f'''You are an SEO specialist for {platform} content.\n",
        "\n",
        "Topic: {topic}\n",
        "\n",
        "1. Suggest 8-12 SEO keywords/phrases.\n",
        "2. Suggest 3 video/post titles optimised for CTR.\n",
        "3. Write a 2-3 paragraph description with those keywords naturally included.\n",
        "4. Suggest 10-15 tags/hashtags.\n",
        "\n",
        "Return JSON ONLY:\n",
        "\n",
        "{{\n",
        "  \"keywords\": [\"...\", \"...\"],\n",
        "  \"titles\": [\"...\", \"...\"],\n",
        "  \"description\": \"...\",\n",
        "  \"tags\": [\"...\", \"...\"]\n",
        "}}\n",
        "'''\n",
        "\n",
        "        response = self.model.generate_content(prompt)\n",
        "        raw = response.text\n",
        "\n",
        "        try:\n",
        "            seo = json.loads(raw)\n",
        "        except Exception:\n",
        "            if \"{\" in raw and \"}\" in raw:\n",
        "                raw_json = raw[raw.find(\"{\"): raw.rfind(\"}\") + 1]\n",
        "                seo = json.loads(raw_json)\n",
        "            else:\n",
        "                raise ValueError(\"Could not parse SEO JSON from Gemini response:\\n\" + raw)\n",
        "\n",
        "        state[\"seo\"] = seo\n",
        "        return state\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c417250",
      "metadata": {
        "id": "4c417250"
      },
      "source": [
        "\n",
        "## 6. Sentiment / Tonality Adjuster Agent\n",
        "\n",
        "One-liner: Rewrites the structured script into a single flowing script while applying the creator's chosen tone.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "50f18a07",
      "metadata": {
        "id": "50f18a07"
      },
      "outputs": [],
      "source": [
        "\n",
        "class ToneAdjusterAgent(Agent):\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def run(self, state: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        structure = state[\"structure\"]\n",
        "        tone = state[\"analysis\"][\"tone\"]\n",
        "\n",
        "        prompt = f'''You are a professional script editor for video creators.\n",
        "\n",
        "Rewrite the following structured script into a single, flowing script,\n",
        "keeping the structure but applying this tone:\n",
        "\"{tone}\" (for example: hype, friendly, professional, storytelling, etc.)\n",
        "\n",
        "Maintain:\n",
        "- Same meaning\n",
        "- Same order of sections\n",
        "\n",
        "Structured script (JSON):\n",
        "{json.dumps(structure)}\n",
        "\n",
        "Return ONLY the final ready-to-read script as plain text,\n",
        "with clear line breaks for each sentence or short phrase,\n",
        "ready for a teleprompter.\n",
        "'''\n",
        "\n",
        "        response = self.model.generate_content(prompt)\n",
        "        script_text = (response.text or \"\").strip()\n",
        "        state[\"tone_adjusted\"] = script_text\n",
        "        return state\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c4c8520",
      "metadata": {
        "id": "1c4c8520"
      },
      "source": [
        "\n",
        "## 7. Final Script Assembler Agent\n",
        "\n",
        "One-liner: Optionally formats or post-processes the tone-adjusted script (currently passes it through as final output).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b15d4e71",
      "metadata": {
        "id": "b15d4e71"
      },
      "outputs": [],
      "source": [
        "\n",
        "class ScriptAssemblerAgent(Agent):\n",
        "    # Currently just passes through the tone-adjusted script.\n",
        "    # Extend this if you want to add [PAUSE] markers, emphasis, etc.\n",
        "    def run(self, state: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        final_script = state.get(\"tone_adjusted\", \"\")\n",
        "        state[\"final_script\"] = final_script\n",
        "        return state\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29bba44f",
      "metadata": {
        "id": "29bba44f"
      },
      "source": [
        "\n",
        "## 8. Thumbnail Caption Generator Agent\n",
        "\n",
        "One-liner: Uses Gemini to generate short, bold thumbnail caption options to drive clicks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "55ca464d",
      "metadata": {
        "id": "55ca464d"
      },
      "outputs": [],
      "source": [
        "\n",
        "class ThumbnailCaptionAgent(Agent):\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def run(self, state: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        topic = state[\"analysis\"][\"topic\"]\n",
        "        hook = state.get(\"structure\", {}).get(\"hook\", \"\")\n",
        "\n",
        "        prompt = f'''You are a YouTube/Instagram thumbnail copy expert.\n",
        "\n",
        "Topic: {topic}\n",
        "Main hook: {hook}\n",
        "\n",
        "Generate 10 ultra-short thumbnail texts:\n",
        "- 2-5 words each\n",
        "- Very bold and emotional\n",
        "- No hashtags, no emojis\n",
        "- Designed for high CTR\n",
        "\n",
        "Return them as a JSON list of strings ONLY:\n",
        "[\"...\", \"...\"]\n",
        "'''\n",
        "\n",
        "        response = self.model.generate_content(prompt)\n",
        "        raw = response.text\n",
        "\n",
        "        try:\n",
        "            thumbs = json.loads(raw)\n",
        "        except Exception:\n",
        "            if \"[\" in raw and \"]\" in raw:\n",
        "                raw_json = raw[raw.find(\"[\"): raw.rfind(\"]\") + 1]\n",
        "                thumbs = json.loads(raw_json)\n",
        "            else:\n",
        "                raise ValueError(\"Could not parse thumbnail caption JSON:\\n\" + raw)\n",
        "\n",
        "        state[\"thumbnail_captions\"] = thumbs\n",
        "        return state\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57247027",
      "metadata": {
        "id": "57247027"
      },
      "source": [
        "\n",
        "## 9. Orchestrator: Chaining All Agents\n",
        "\n",
        "One-liner: Runs all agents in sequence to transform the raw input into hooks, SEO metadata, final script and thumbnail captions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "6c15b401",
      "metadata": {
        "id": "6c15b401"
      },
      "outputs": [],
      "source": [
        "\n",
        "class ScriptRewriterOrchestrator:\n",
        "    def __init__(self, model):\n",
        "        self.agents: List[Agent] = [\n",
        "            IngestionAgent(),\n",
        "            HookGeneratorAgent(model),\n",
        "            StructureOptimizerAgent(model),\n",
        "            SEOKeywordAgent(model),\n",
        "            ToneAdjusterAgent(model),\n",
        "            ScriptAssemblerAgent(),\n",
        "            ThumbnailCaptionAgent(model),\n",
        "        ]\n",
        "\n",
        "    def run(self, script_input: ScriptInput) -> ScriptOutput:\n",
        "        state: Dict[str, Any] = {\"input\": script_input}\n",
        "        for agent in self.agents:\n",
        "            state = agent.run(state)\n",
        "\n",
        "        return ScriptOutput(\n",
        "            hooks=state.get(\"hooks\", []),\n",
        "            structured_script=json.dumps(state.get(\"structure\", {}), indent=2),\n",
        "            seo_metadata=state.get(\"seo\", {}),\n",
        "            final_script=state.get(\"final_script\", \"\"),\n",
        "            thumbnail_captions=state.get(\"thumbnail_captions\", [])\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbb0e62a",
      "metadata": {
        "id": "bbb0e62a"
      },
      "source": [
        "\n",
        "## 10. Demo: Run the Full Pipeline on a Sample Script\n",
        "\n",
        "Edit the `ScriptInput` below with your own topic, draft script, platform and tone, then run the cell to see:\n",
        "- Generated hooks  \n",
        "- SEO metadata  \n",
        "- Final ready-to-record script  \n",
        "- Thumbnail caption ideas  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "ddfdb65b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ddfdb65b",
        "outputId": "a741be35-75fb-4aa7-efe1-5c985bc4460c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Listing available models:\n",
            "models/gemini-2.5-flash\n",
            "models/gemini-2.5-pro\n",
            "models/gemini-2.0-flash-exp\n",
            "models/gemini-2.0-flash\n",
            "models/gemini-2.0-flash-001\n",
            "models/gemini-2.0-flash-lite-001\n",
            "models/gemini-2.0-flash-lite\n",
            "models/gemini-2.0-flash-lite-preview-02-05\n",
            "models/gemini-2.0-flash-lite-preview\n",
            "models/gemini-exp-1206\n",
            "models/gemini-2.5-flash-preview-tts\n",
            "models/gemini-2.5-pro-preview-tts\n",
            "models/gemma-3-1b-it\n",
            "models/gemma-3-4b-it\n",
            "models/gemma-3-12b-it\n",
            "models/gemma-3-27b-it\n",
            "models/gemma-3n-e4b-it\n",
            "models/gemma-3n-e2b-it\n",
            "models/gemini-flash-latest\n",
            "models/gemini-flash-lite-latest\n",
            "models/gemini-pro-latest\n",
            "models/gemini-2.5-flash-lite\n",
            "models/gemini-2.5-flash-image-preview\n",
            "models/gemini-2.5-flash-image\n",
            "models/gemini-2.5-flash-preview-09-2025\n",
            "models/gemini-2.5-flash-lite-preview-09-2025\n",
            "models/gemini-3-pro-preview\n",
            "models/gemini-3-pro-image-preview\n",
            "models/nano-banana-pro-preview\n",
            "models/gemini-robotics-er-1.5-preview\n",
            "models/gemini-2.5-computer-use-preview-10-2025\n",
            "models/deep-research-pro-preview-12-2025\n",
            "=== GENERATED HOOKS ===\n",
            "1. Here are 7 scroll-stopping hooks for your video:\n",
            "2. AI job dream? Transform your resume with killer projects!\n",
            "3. Stop resume rejections! Add AI projects recruiters LOVE.\n",
            "4. Unlock your AI career: Make projects POP on your resume.\n",
            "5. No experience? Your AI projects ARE your resume power-up!\n",
            "6. Get hired faster! The AI resume project strategy you need.\n",
            "7. Stand out! Turn your AI projects into interview magnets.\n",
            "8. The simple trick: AI projects that recruiters can't ignore.\n",
            "=== SEO METADATA (titles) ===\n",
            "- Boost Your AI Engineer Resume: How to Add Impactful Projects\n",
            "- Stand Out! 5 AI Projects That Will Land You The Engineer Job\n",
            "- Crafting the Perfect AI Resume: Showcase Your Projects Like a Pro\n",
            "=== FINAL READY-TO-RECORD SCRIPT ===\n",
            "Hey you!\n",
            "Are you tired of your awesome AI projects not getting the attention they deserve on your resume?\n",
            "Want to stop those frustrating rejections?\n",
            "Get ready, because I'm about to show you how to craft AI project descriptions that recruiters absolutely LOVE!\n",
            "\n",
            "Landing an AI Engineer role today?\n",
            "Whew, it's competitive out there, and a bland, generic resume just isn't going to cut it anymore.\n",
            "Recruiters aren't looking for buzzwords; they want tangible, undeniable proof of your brilliant abilities!\n",
            "And guess what? Your AI projects are your secret weapon.\n",
            "In just a few minutes, I'm going to spill the beans on exactly how to make your projects grab attention and help you land that dream job!\n",
            "\n",
            "Alright, let's dive into tip number one, and it's a biggie!\n",
            "Your projects need to scream your core AI skills from the rooftops.\n",
            "But don't just show you *can* code!\n",
            "We're talking about showcasing comprehensive model training and fine-tuning.\n",
            "Highlight your robust data preprocessing and feature engineering skills.\n",
            "And crucially, can you take that amazing model and deploy it or integrate it into a real-world setting?\n",
            "Show them you don't just build, but you clean, you optimize, and you make your AI solutions *work* in the wild!\n",
            "\n",
            "Next up, let's talk about your powerful tech stack!\n",
            "Don't be shy – explicitly mention every single tool and technology you've mastered.\n",
            "Recruiters aren't mind readers, so don't assume they'll just *know* you used Python, TensorFlow, or PyTorch.\n",
            "List those specific programming languages and frameworks.\n",
            "Did you integrate any cool APIs? Tell them!\n",
            "And this is huge: highlight any cloud platforms like AWS, Azure, or GCP, or MLOps tools like MLflow or Kubeflow you rocked.\n",
            "This screams \"production-ready\" and \"professional capability\"!\n",
            "\n",
            "Alright, for our grand finale, let's make your project descriptions shine!\n",
            "We're going to keep each one crisp, impactful, and super results-oriented.\n",
            "Here's your magic formula: Problem-Solution-Impact.\n",
            "First, state the specific, real-world problem you courageously tackled.\n",
            "Then, describe the awesome solution you *built*, using all those skills and tools we just talked about.\n",
            "And here's where the magic truly happens: quantify the measurable impact!\n",
            "Did you improve accuracy by X%? Reduce processing time by Y%? Or achieve a massive Z business goal?\n",
            "Remember, numbers don't just speak louder than words; they practically shout your success!\n",
            "\n",
            "I'm super curious now!\n",
            "What's the most challenging or rewarding AI project you've tackled for your portfolio?\n",
            "Share your experiences and any pro tips you have in the comments below – I'd absolutely love to hear them!\n",
            "\n",
            "If these tips just supercharged your AI resume to superhero status, then hit that like button right now!\n",
            "And for even more actionable advice on breaking into and absolutely thriving in the incredible world of AI, make sure to subscribe to the channel and ring that notification bell!\n",
            "That way, you'll never miss an update that could change your career!\n",
            "=== THUMBNAIL CAPTION IDEAS ===\n",
            "- STOP Resume Rejection!\n",
            "- Recruiters DEMAND This AI!\n",
            "- Killer AI Projects NOW!\n",
            "- Get Hired: AI Projects!\n",
            "- Your AI Job Awaits!\n",
            "- AI Resume Secret REVEALED!\n",
            "- NEVER Get Rejected Again!\n",
            "- Land Your Dream AI Role!\n",
            "- Build AI Recruiters LOVE!\n",
            "- Unlock Your AI Career!\n"
          ]
        }
      ],
      "source": [
        "# Example usage demo\n",
        "sample_input = ScriptInput(\n",
        "    topic=\"How to add AI engineer related projects in RESUME\",\n",
        "    draft_script=\"\"\"Want to make your resume stand out for AI Engineer roles?\n",
        "    Add projects that clearly showcase your skills—like model training,\n",
        "    data preprocessing, and real-world deployment. Highlight the tools you\n",
        "    used such as Python, TensorFlow or PyTorch, APIs, and cloud or MLOps\n",
        "    platforms. Keep each project crisp by stating the problem, the solution\n",
        "    you built, and the measurable impact it created.\n",
        "\"\"\",\n",
        "    platform=\"YOUTUBE\",\n",
        "    tone=\"friendly, hype, beginner-friendly\"\n",
        ")\n",
        "\n",
        "# Re-configure the model with the correct 'models/' prefix\n",
        "# Listing available models to debug 'NotFound' error.\n",
        "print(\"Listing available models:\")\n",
        "for m in genai.list_models():\n",
        "    if \"generateContent\" in m.supported_generation_methods:\n",
        "        print(m.name)\n",
        "\n",
        "# If 'gemini-1.5-flash' is not in the list above, you might need to choose a different model.\n",
        "MODEL_NAME = \"models/gemini-2.5-flash\" # Updated to an available model\n",
        "model = genai.GenerativeModel(MODEL_NAME)\n",
        "\n",
        "orchestrator = ScriptRewriterOrchestrator(model)\n",
        "output = orchestrator.run(sample_input)\n",
        "\n",
        "print(\"=== GENERATED HOOKS ===\")\n",
        "for i, h in enumerate(output.hooks, 1):\n",
        "    print(f\"{i}. {h}\")\n",
        "\n",
        "print(\"=== SEO METADATA (titles) ===\")\n",
        "for t in output.seo_metadata.get(\"titles\", []):\n",
        "    print(\"-\", t)\n",
        "\n",
        "print(\"=== FINAL READY-TO-RECORD SCRIPT ===\")\n",
        "print(output.final_script)\n",
        "\n",
        "print(\"=== THUMBNAIL CAPTION IDEAS ===\")\n",
        "for t in output.thumbnail_captions:\n",
        "    print(\"-\", t)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}